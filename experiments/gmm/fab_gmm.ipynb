{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wzkwds/1Prompt1Story/blob/main/experiments/gmm/fab_gmm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7gv_8Zk18XQ",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lollcat/fab-torch/blob/master/experiments/gmm/fab_gmm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pIuF7gAmLbpI",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Setup Repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "U21CxXjHRcsF",
        "pycharm": {
          "name": "#%%\n"
        },
        "outputId": "abd0fbcd-8d39-42f8-dc3e-603ee296d3cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fab-torch'...\n",
            "remote: Enumerating objects: 3496, done.\u001b[K\n",
            "remote: Counting objects: 100% (420/420), done.\u001b[K\n",
            "remote: Compressing objects: 100% (191/191), done.\u001b[K\n",
            "remote: Total 3496 (delta 252), reused 262 (delta 222), pack-reused 3076 (from 1)\u001b[K\n",
            "Receiving objects: 100% (3496/3496), 272.53 MiB | 18.30 MiB/s, done.\n",
            "Resolving deltas: 100% (2510/2510), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/lollcat/fab-torch.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tmsNqL0lRwGa",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.listdir()\n",
        "os.chdir(\"fab-torch\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "d7eC5CsoRs_d",
        "pycharm": {
          "name": "#%%\n"
        },
        "outputId": "0f12cb80-7c19-4e35-f41f-dfd38d42c4b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /content/fab-torch\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting boltzgen@ git+https://github.com/VincentStimper/boltzmann-generators.git (from fab==0.1)\n",
            "  Cloning https://github.com/VincentStimper/boltzmann-generators.git to /tmp/pip-install-9bn9qkfl/boltzgen_8563d236d70b426bacbbe1aa7dd46e49\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/VincentStimper/boltzmann-generators.git /tmp/pip-install-9bn9qkfl/boltzgen_8563d236d70b426bacbbe1aa7dd46e49\n",
            "  Resolved https://github.com/VincentStimper/boltzmann-generators.git to commit 2b177fc155f533933489b8fce8d6483ebad250d3\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting larsflow@ git+https://github.com/VincentStimper/resampled-base-flows.git (from fab==0.1)\n",
            "  Cloning https://github.com/VincentStimper/resampled-base-flows.git to /tmp/pip-install-9bn9qkfl/larsflow_32ea5333f36c4c4b9437d338d1dc6f90\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/VincentStimper/resampled-base-flows.git /tmp/pip-install-9bn9qkfl/larsflow_32ea5333f36c4c4b9437d338d1dc6f90\n",
            "  Resolved https://github.com/VincentStimper/resampled-base-flows.git to commit 18db5bf28ffa1d5ab9ef2b63856e186affee604b\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from fab==0.1) (2.0.2)\n",
            "INFO: pip is looking at multiple versions of fab to determine which version is compatible with other requirements. This could take a while.\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.13.1 (from fab) (from versions: 2.2.0, 2.2.1, 2.2.2, 2.3.0, 2.3.1, 2.4.0, 2.4.1, 2.5.0, 2.5.1, 2.6.0, 2.7.0, 2.7.1, 2.8.0)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.13.1\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade ."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install normflows"
      ],
      "metadata": {
        "id": "60LVbnTxQNeZ",
        "outputId": "3fbedcf6-32dd-4566-b547-b54c6aa9bfba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting normflows\n",
            "  Downloading normflows-1.7.3.tar.gz (65 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/65.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.3/65.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from normflows) (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from normflows) (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->normflows) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->normflows) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->normflows) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->normflows) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->normflows) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->normflows) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->normflows) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->normflows) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->normflows) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->normflows) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->normflows) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->normflows) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->normflows) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->normflows) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->normflows) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->normflows) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->normflows) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->normflows) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->normflows) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->normflows) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->normflows) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->normflows) (3.4.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->normflows) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->normflows) (3.0.2)\n",
            "Building wheels for collected packages: normflows\n",
            "  Building wheel for normflows (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for normflows: filename=normflows-1.7.3-py2.py3-none-any.whl size=87247 sha256=117f743b3a8be1436cfe1f950c0d4296ceec4b439447c1a89dad3a27e3a2566a\n",
            "  Stored in directory: /root/.cache/pip/wheels/f7/b4/37/a3acc21799a058d6fe15127321dcdf99826f438bb591accafa\n",
            "Successfully built normflows\n",
            "Installing collected packages: normflows\n",
            "Successfully installed normflows-1.7.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ajs-kTgLeWU",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Let's go!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeFLDH5mLhv9",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Lzkmrn81LajP",
        "pycharm": {
          "name": "#%%\n"
        },
        "outputId": "89a3fdef-7516-4867-a033-59abcadba48d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'normflows'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4223099981.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnormflows\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'normflows'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import normflows as nf\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "from fab import FABModel, HamiltonianMonteCarlo, Metropolis\n",
        "from fab.utils.logging import ListLogger\n",
        "from fab.utils.plotting import plot_history, plot_contours, plot_marginal_pair\n",
        "from fab.target_distributions.gmm import GMM\n",
        "from fab.utils.prioritised_replay_buffer import PrioritisedReplayBuffer\n",
        "from fab import Trainer, PrioritisedBufferTrainer\n",
        "from fab.utils.plotting import plot_contours, plot_marginal_pair\n",
        "\n",
        "\n",
        "from experiments.make_flow import make_wrapped_normflow_realnvp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHtMPbFlMKvd",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Setup Target distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kkr2CqqDMRBn",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "dim = 2\n",
        "n_mixes = 40\n",
        "loc_scaling = 40.0  # scale of the problem (changes how far apart the modes of each Guassian component will be)\n",
        "log_var_scaling = 1.0 # variance of each Gaussian\n",
        "seed = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qM9PUDE3MMoA",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)  # seed of 0 for GMM problem\n",
        "target = GMM(dim=dim, n_mixes=n_mixes,\n",
        "              loc_scaling=loc_scaling, log_var_scaling=log_var_scaling,\n",
        "              use_gpu=True, true_expectation_estimation_n_samples=int(1e5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxMmszREPEY1",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# plot target\n",
        "target.to(\"cpu\")\n",
        "fig, ax = plt.subplots()\n",
        "plotting_bounds = (-loc_scaling * 1.4, loc_scaling * 1.4)\n",
        "plot_contours(target.log_prob, bounds=plotting_bounds, n_contour_levels=80, ax=ax, grid_width_n_points=200)\n",
        "target.to(\"cuda\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJmoBOJ8REZO",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Create FAB model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xp58k3FMQ3Qf",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# hyper-parameters\n",
        "\n",
        "# Flow\n",
        "n_flow_layers = 15\n",
        "layer_nodes_per_dim = 40\n",
        "lr = 1e-4\n",
        "max_gradient_norm = 100.0\n",
        "batch_size = 128\n",
        "n_iterations = 4000\n",
        "n_eval = 10\n",
        "eval_batch_size = batch_size * 10\n",
        "n_plots = 10 # number of plots shows throughout tranining\n",
        "use_64_bit = True\n",
        "alpha = 2.0\n",
        "\n",
        "# AIS\n",
        "# By default we use a simple metropolis mcmc transition with a fixed step size.\n",
        "# Can switch this to 'hmc' to improve training efficiency.\n",
        "transition_operator_type = \"metropolis\"\n",
        "n_intermediate_distributions = 1\n",
        "metropolis_step_size = 5.0\n",
        "\n",
        "# buffer config\n",
        "n_batches_buffer_sampling = 4\n",
        "maximum_buffer_length = batch_size * n_batches_buffer_sampling * 100\n",
        "min_buffer_length = batch_size * n_batches_buffer_sampling * 10\n",
        "\n",
        "# target p^\\alpha q^{a-\\alpha} as target for AIS.\n",
        "min_is_target = True\n",
        "p_target = not min_is_target # Whether to use p as the target."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3P5c29Rayd2B",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "if use_64_bit:\n",
        "    torch.set_default_dtype(torch.float64)\n",
        "    target = target.double()\n",
        "    print(f\"running with 64 bit\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRJx0FhTRKIF",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Setup flow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ptJrkMn5Qz2F",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "flow = make_wrapped_normflow_realnvp(dim, n_flow_layers=n_flow_layers,\n",
        "                                 layer_nodes_per_dim=layer_nodes_per_dim,\n",
        "                                act_norm = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNhmNi0zRMT2",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Setup Transition operator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAfUX8rgQ9XG",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "if transition_operator_type == \"hmc\":\n",
        "    # very lightweight HMC.\n",
        "    transition_operator = HamiltonianMonteCarlo(\n",
        "            n_ais_intermediate_distributions=n_intermediate_distributions,\n",
        "            dim=dim,\n",
        "            base_log_prob=flow.log_prob,\n",
        "            target_log_prob=target.log_prob,\n",
        "            alpha=alpha,\n",
        "            p_target=p_target,\n",
        "        n_outer=1,\n",
        "        epsilon=1.0, L=5)\n",
        "elif transition_operator_type == \"metropolis\":\n",
        "    transition_operator = Metropolis(\n",
        "        n_ais_intermediate_distributions=n_intermediate_distributions,\n",
        "        dim=dim,\n",
        "        base_log_prob=flow.log_prob,\n",
        "        target_log_prob=target.log_prob,\n",
        "        p_target=p_target,\n",
        "        alpha=alpha,\n",
        "        n_updates=1,\n",
        "        adjust_step_size=False,\n",
        "        max_step_size=metropolis_step_size, # the same for all metropolis steps\n",
        "        min_step_size=metropolis_step_size,\n",
        "        eval_mode=False,\n",
        "                                  )\n",
        "else:\n",
        "    raise NotImplementedError"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIQthDLyLkus",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Setup FAB model with prioritised replay buffer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFrJvytJcAm2",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# use GPU if available\n",
        "if torch.cuda.is_available():\n",
        "    flow.cuda()\n",
        "    transition_operator.cuda()\n",
        "    target.to(\"cuda\")\n",
        "    print(f\"Running with GPU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SgXAZZpCSAiK",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "fab_model = FABModel(flow=flow,\n",
        "                     target_distribution=target,\n",
        "                     n_intermediate_distributions=n_intermediate_distributions,\n",
        "                     transition_operator=transition_operator,\n",
        "                     alpha=alpha)\n",
        "optimizer = torch.optim.Adam(flow.parameters(), lr=lr)\n",
        "logger = ListLogger(save=False) # save training history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5onsUCTJbE-l",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Setup buffer.\n",
        "def initial_sampler():\n",
        "  # fill replay buffer using initialised model and AIS.\n",
        "    point, log_w = fab_model.annealed_importance_sampler.sample_and_log_weights(\n",
        "            batch_size, logging=False)\n",
        "    return point.x, log_w, point.log_q\n",
        "buffer = PrioritisedReplayBuffer(dim=dim, max_length=maximum_buffer_length,\n",
        "                      min_sample_length=min_buffer_length,\n",
        "                      initial_sampler=initial_sampler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2QJeaj5Ll4o",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "def plot(fab_model, n_samples = 128):\n",
        "    fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
        "    target.to(\"cpu\")\n",
        "    plot_contours(target.log_prob, bounds=plotting_bounds, ax=axs[0], n_contour_levels=50, grid_width_n_points=200)\n",
        "    plot_contours(target.log_prob, bounds=plotting_bounds, ax=axs[1], n_contour_levels=50, grid_width_n_points=200)\n",
        "    plot_contours(target.log_prob, bounds=plotting_bounds, ax=axs[2], n_contour_levels=50, grid_width_n_points=200)\n",
        "    target.to(\"cuda\")\n",
        "\n",
        "    # plot flow samples\n",
        "    samples_flow = fab_model.flow.sample((n_samples,)).detach()\n",
        "    plot_marginal_pair(samples_flow, ax=axs[0], bounds=plotting_bounds)\n",
        "\n",
        "\n",
        "    # plot ais samples\n",
        "    samples_ais = fab_model.annealed_importance_sampler.sample_and_log_weights(n_samples,\n",
        "                                                                               logging=False)[0].x\n",
        "    plot_marginal_pair(samples_ais, ax=axs[1], bounds=plotting_bounds)\n",
        "\n",
        "    # plot buffer samples\n",
        "    samples_buffer = buffer.sample(n_samples)[0].detach()\n",
        "    plot_marginal_pair(samples_buffer, ax=axs[2], bounds=plotting_bounds)\n",
        "\n",
        "    axs[0].set_title(\"flow samples\")\n",
        "    axs[1].set_title(\"ais samples\")\n",
        "    axs[2].set_title(\"buffer samples\")\n",
        "    plt.show()\n",
        "    return [fig]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecjfGOS2bWEq",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "plot(fab_model) # Visualise model during initialisation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zfjeD4Udb275",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Setup trainer.\n",
        "trainer = PrioritisedBufferTrainer(model=fab_model, optimizer=optimizer,\n",
        "              logger=logger, plot=plot,\n",
        "              buffer=buffer,\n",
        "              n_batches_buffer_sampling=n_batches_buffer_sampling,\n",
        "              max_gradient_norm=max_gradient_norm,\n",
        "              alpha=alpha,\n",
        "              w_adjust_max_clip=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ailsWaOwdF5V",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Train model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3a8E010fJ_0",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "This problem is quite challenging for training, as the flow has a very poor initialisation, and therefore often places extremely small probability on samples in new modes.\n",
        "\n",
        "This causes some **numerical instability**: There are lots of NaN errors throughout training, due to (1) numerical sinstability in the flow itself causing the flow to generate NaN samples or samples with large values that have NaN log prob under the target, as well as (2) sometimes AIS finds regions in the target with negligible mass under the flow.  However, these numerical instabilities do not prevent training from suceeding."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZ8ohs7a1vAu",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Now run!\n",
        "trainer.run(n_iterations=n_iterations, batch_size=batch_size, n_plot=n_plots, \\\n",
        "            n_eval=n_eval, eval_batch_size=eval_batch_size, save=False)  # note that the progress bar during training prints ESS w.r.t p^2/q."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EH1zl3bQ1vAu",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "In the below plot of samples from the flow vs the target contours, and with the test set log prob throughout training, we see that the flow covers the target distribution quite well. It may be trained further to obtain even better results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87HoslTI1vAy",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Test set probability using samples from the target distribution.\n",
        "eval_iters = np.linspace(0, n_iterations, n_eval)\n",
        "plt.plot(eval_iters, logger.history['flow_test_set_mean_log_prob_p_target'])\n",
        "plt.ylabel(\"mean test set log prob\")\n",
        "plt.xlabel(\"eval iteration\")\n",
        "plt.yscale(\"symlog\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUxcXo501vAz",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(1, 1, figsize=(5, 5))\n",
        "target.to(\"cpu\")\n",
        "plot_contours(target.log_prob, bounds=plotting_bounds, ax=axs, n_contour_levels=50, grid_width_n_points=200)\n",
        "target.to(\"cuda\")\n",
        "\n",
        "n_samples = 1000\n",
        "samples_flow = fab_model.flow.sample((n_samples,)).detach()\n",
        "plot_marginal_pair(samples_flow, ax=axs, bounds=plotting_bounds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bbz9vZ4F1vAz",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Training a flow by reverse KL divergence minimisation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-N5dD_x1vAz",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "loss_type = \"flow_reverse_kl\" # can set to \"target_foward_kl\" for training by maximum likelihood of samples from the GMM target."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-e7Gg6Oj1vAz",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Create flow using the same architecture.\n",
        "flow = make_wrapped_normflow_realnvp(dim, n_flow_layers=n_flow_layers,\n",
        "                                 layer_nodes_per_dim=layer_nodes_per_dim,\n",
        "                                act_norm = False)\n",
        "optimizer = torch.optim.Adam(flow.parameters(), lr=lr)\n",
        "logger = ListLogger(save=False) # save training history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ieE0Maj01vA0",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# use GPU if available\n",
        "if torch.cuda.is_available():\n",
        "  flow.cuda()\n",
        "  transition_operator.cuda()\n",
        "  target.to(\"cuda\")\n",
        "  print(f\"Running with GPU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIj8V3WR1vA0",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "n_iterations = int(3*(n_iterations)) # Training the flow by KL minimisation is cheaper per iteration, so we run it for more iterations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cey61dub1vA0",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "reverse_kld_model = FABModel(flow=flow,\n",
        "                     target_distribution=target,\n",
        "                     n_intermediate_distributions=n_intermediate_distributions,\n",
        "                     transition_operator=transition_operator,\n",
        "                     loss_type=loss_type,\n",
        "                     alpha=1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VZrrkep1vA7",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "def plot_flow_reverse_kld(fab_model, n_samples = 300):\n",
        "    fig, axs = plt.subplots(1,1, figsize=(4, 4))\n",
        "    target.to(\"cpu\")\n",
        "    plot_contours(target.log_prob, bounds=plotting_bounds, ax=axs, n_contour_levels=50, grid_width_n_points=200)\n",
        "    target.to(\"cuda\")\n",
        "\n",
        "    # plot flow samples\n",
        "    samples_flow = fab_model.flow.sample((n_samples,))\n",
        "    plot_marginal_pair(samples_flow, ax=axs, bounds=plotting_bounds)\n",
        "\n",
        "    axs.set_title(\"flow samples\")\n",
        "    plt.show()\n",
        "    return [fig]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MelWKsN_1vA8",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(model=reverse_kld_model, optimizer=optimizer, logger=logger, plot=plot_flow_reverse_kld, max_gradient_norm=max_gradient_norm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8SaB2BL1vA8",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Now run!\n",
        "trainer.run(n_iterations=n_iterations, batch_size=batch_size, n_plot=n_plots, \\\n",
        "            n_eval=n_eval, eval_batch_size=eval_batch_size, save=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAUDI5lNweY_",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "We evaluate the flow on samples from the target distribution, we see that because the flow trained by kl divergence minimisation is missing modes, the flow places NaN log prob on samples from the target."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kTDrcaa5wK9g",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "logger.history[\"flow_test_set_mean_log_prob\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cyLoMV8VvOSE",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "eval_iters = np.linspace(0, n_iterations, n_eval)\n",
        "plt.plot(eval_iters, logger.history[\"flow_test_set_mean_log_prob\"])\n",
        "plt.ylabel(\"mean test set log prob\")\n",
        "plt.xlabel(\"eval iteration\")\n",
        "plt.yscale(\"symlog\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Y_h1lGvvVMD",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}